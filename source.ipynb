{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "operating-harvard",
   "metadata": {},
   "source": [
    "# Advanced Programming Summative Assessment\n",
    "\n",
    "**Objective**: \n",
    "To design and develop a prototype application \n",
    "that demonstrates how data from the given data set can be \n",
    "formatted, cleaned, and used to generate specific outputs \n",
    "\n",
    "**Date**: 1st May, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-exploration",
   "metadata": {},
   "source": [
    "**Contents**\n",
    "\n",
    "- [1 Global environment](#env)\n",
    "- [2 Import packages](#import)\n",
    "- [3 Global Variables](#glob)\n",
    "- [4 Status Bar](#bar)\n",
    "- [5 Styling](#Style)\n",
    "- [6 Functions](#func)\n",
    "    - [6.1 Status Messages](#status_msg)\n",
    "    - [6.2 Export to JSON](#json)\n",
    "    - [6.3 Exit](#exit)\n",
    "    - [6.4 Upload/Browse for Files](#upload)\n",
    "    - [6.5 Generic Clean](#generic)\n",
    "    - [6.6 Select Types](#select_type)\n",
    "    - [6.7 Clean File Function Button](#clean_button)\n",
    "    - [6.8 Data Wrangling](#data_wrangling)\n",
    "    - [6.9 Calculate Statistics](#calculate)\n",
    "    - [6.10 Table of Statistics](#table)\n",
    "    - [6.11 Create Graphs](#start_graphs)\n",
    "    - [6.12 Box-and-Whisker Plots](#box_whisker)\n",
    "    - [6.13 Histograms](#histograms)\n",
    "    - [6.14 Graphs Function Button](#graph_selection)\n",
    "    - [6.15 Visualize Data](#visualize_data)\n",
    "    - [6.16 Export Graphs](#export_graphs)\n",
    "- [7 Contents](#content)\n",
    "    - [7.1 Tab 1: Data Cleaning](#tab1)\n",
    "    - [7.2 Tab 2: Data Visualization](#tab2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-vocabulary",
   "metadata": {},
   "source": [
    "<a name='env'></a>\n",
    "# 1 Global environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outer-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.7\n"
     ]
    }
   ],
   "source": [
    "# check the python version on Anaconda \n",
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-theater",
   "metadata": {},
   "source": [
    "<a name='import'></a>\n",
    "# 2 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addressed-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # handle JSON file\n",
    "import os  # File Input/Output\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "import matplotlib.cbook as cbook\n",
    "import tkinter as tk # GUI application\n",
    "from tkinter import ttk\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import asksaveasfile \n",
    "from tkinter.filedialog import asksaveasfilename\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from datetime import datetime # datetime object manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brave-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization in new window\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-wealth",
   "metadata": {},
   "source": [
    "<a name='glob'></a>\n",
    "# 3 Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "environmental-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values\n",
    "missing_values = [\"NA\", \"NaN\", \"N/A\", \"na\", r\"^\\s*$\", \"\", \" \"]\n",
    "\n",
    "# create instance of Tk class\n",
    "window = tk.Tk()\n",
    "window.title(\"Data Analysis Tool\")\n",
    "\n",
    "# disable windows from resizing\n",
    "window.resizable(False, False)  \n",
    "\n",
    "# window sizing\n",
    "window_height = 380\n",
    "window_width = 700\n",
    "screen_width = window.winfo_screenwidth()\n",
    "screen_height = window.winfo_screenheight()\n",
    "\n",
    "# place window in the middle of screen\n",
    "x_coordinate = int((screen_width/2) - (window_width/2))\n",
    "y_coordinate = int((screen_height/2) - (window_height/2))\n",
    "window.geometry(\"{}x{}+{}+{}\".format(window_width, window_height, x_coordinate, y_coordinate))\n",
    "\n",
    "# add Tabs to window \n",
    "tab_control = ttk.Notebook(window)\n",
    "clean_tab = ttk.Frame(tab_control)\n",
    "graph_tab = ttk.Frame(tab_control)\n",
    "\n",
    "# add text to tab and styling \n",
    "tab_control.add(clean_tab, text=\"1. Data Cleaning\")\n",
    "tab_control.add(graph_tab, text=\"2. Data Visualization\")\n",
    "tab_control.pack(expand=1, fill=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-timber",
   "metadata": {},
   "source": [
    "<a name='bar'></a>\n",
    "# 4 Status Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuous-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_text = StringVar(window)\n",
    "status_text.set(\"Please load your files by clicking the 'Browse' button(s).\")\n",
    "status_bar = Label(window, textvariable=status_text, bd=1, relief=tk.SUNKEN, font=('Helvetica', 12, 'normal'))\n",
    "status_bar.configure(foreground='green')\n",
    "status_bar.pack(side=BOTTOM, fill=X)\n",
    "status_bar.config(background='#F9F9F9', relief=RAISED, height=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-opera",
   "metadata": {},
   "source": [
    "<a name='Style'></a>\n",
    "# 5 Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "frequent-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default text styling\n",
    "style = ttk.Style()\n",
    "style.configure(\n",
    "    \"STD.Label\",\n",
    "    foreground=\"navy\",\n",
    "    font=\"Helvetica\",\n",
    "    fontsize=8\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-colonial",
   "metadata": {},
   "source": [
    "<a name='func'></a>\n",
    "# 6 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-surprise",
   "metadata": {},
   "source": [
    "<a name='status_msg'></a>\n",
    "## 6.1 Status Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "innovative-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_preparing():\n",
    "    \"\"\"\n",
    "    Show Status of \"Preparing to clean loaded files---\".\n",
    "    \"\"\"\n",
    "    status_bar.configure(foreground='green')\n",
    "    status_text.set(\"*STATUS* Preparing to clean loaded files---\")\n",
    "\n",
    "def status_exported():\n",
    "    \"\"\"\n",
    "    Show Status of exporting data files.\n",
    "    \"\"\"\n",
    "    status_text.set(\"*SUCCESS* You have exported the data files!\")\n",
    "    status_bar.configure(foreground='green')\n",
    "\n",
    "def status_cleaned():\n",
    "    \"\"\"\n",
    "    Show Status of 'All files are cleaned'.\n",
    "    \"\"\"\n",
    "    status_bar.configure(foreground='green')\n",
    "    status_text.set(\"*SUCCESS* All files are cleaned!\")\n",
    "    \n",
    "def error_files():\n",
    "    \"\"\"\n",
    "    Show Status of error with file(s).\n",
    "    \"\"\"\n",
    "    status_bar.configure(foreground='red')\n",
    "    status_text.set('*ERROR* There is a problem with your file(s), please check before exporting!')\n",
    "    print(\"There is a problem with your files, please check before exporting!\")\n",
    "\n",
    "def error_location():\n",
    "    \"\"\"\n",
    "    Show Status of error with file location.\n",
    "    \"\"\"\n",
    "    status_bar.configure(foreground='red')\n",
    "    status_text.set('*ERROR* Please load valid location for the data file by clicking \"Browse\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-upset",
   "metadata": {},
   "source": [
    "<a name='json'></a>\n",
    "## 6.2 Export to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strategic-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_json(file):\n",
    "    \"\"\"\n",
    "    Export cleaned file as JSON file.\n",
    "    \"\"\"\n",
    "    global status_bar, new_json_name, file_name\n",
    "    file_name = \"output\"\n",
    "    if len(input_filename.get()) != 0:\n",
    "        file_name = input_filename.get()\n",
    "    else: \n",
    "        file_name = \"output\"\n",
    "    try:\n",
    "        # New json name\n",
    "        new_json_name = file_name + \".json\"\n",
    "        file.to_json(new_json_name, index='true') \n",
    "        status_exported()  \n",
    "    except NameError:\n",
    "        error_files() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-jordan",
   "metadata": {},
   "source": [
    "<a name='exit'></a>\n",
    "## 6.3 Exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "signed-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit():\n",
    "    \"\"\"\n",
    "    Exit Program.\n",
    "    \"\"\"\n",
    "    if messagebox.askokcancel(\"Exit Program\", \"Click OK to exit the program.\"):\n",
    "        window.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-mortgage",
   "metadata": {},
   "source": [
    "<a name='upload'></a>\n",
    "## 6.4 Upload/Browse for Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "urban-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_1():\n",
    "    \"\"\"\n",
    "    Browse Airport Data File to upload function.\n",
    "    \"\"\"\n",
    "    global df_airport, status_bar\n",
    "    try:\n",
    "        # open csv file only\n",
    "        file = filedialog.askopenfile(filetypes =[('Data Files', '*.csv')])\n",
    "        # fill in missing value with NaN\n",
    "        df_airport = pd.read_csv(file.name,keep_default_na=False, na_values=missing_values)\n",
    "        input_text = file.name\n",
    "        # update input field with file upload directory/path\n",
    "        input_airport.delete(0, tk.END)\n",
    "        input_airport.insert(0, input_text)\n",
    "    except AttributeError:\n",
    "        status_bar.configure(foreground='red')\n",
    "        status_text.set('*ERROR* Please open a valid location for the Airport Data file')\n",
    "        print(\"Please open a valid location for the Airport Data file\")    \n",
    "    \n",
    "def open_file_2():\n",
    "    \"\"\"\n",
    "    Browse Runway Data File to upload function.\n",
    "    \"\"\"\n",
    "    global df_runway\n",
    "    try:\n",
    "        file = filedialog.askopenfile(filetypes =[('Data Files', '*.csv')])\n",
    "        df_runway = pd.read_csv(file.name,keep_default_na=False, na_values=missing_values)   \n",
    "        input_text = file.name\n",
    "        # update input field with file upload directory/path\n",
    "        input_runway.delete(0, tk.END)\n",
    "        input_runway.insert(0, input_text)\n",
    "    except AttributeError:\n",
    "        status_bar.configure(foreground='red')\n",
    "        status_text.set('*ERROR* Please open a valid location for the Runway Data file')\n",
    "        print(\"Please open a valid location for the Runway Data file\")    \n",
    "\n",
    "def open_file_3():\n",
    "    \"\"\"\n",
    "    Browse Airport-Frequency Data File to upload function.\n",
    "    \"\"\"\n",
    "    global df_frequency\n",
    "    try:\n",
    "        file = filedialog.askopenfile(filetypes =[('Data Files', '*.csv')])\n",
    "        df_frequency = pd.read_csv(file.name,keep_default_na=False, na_values=missing_values)\n",
    "        input_text = file.name\n",
    "        # update input field with file upload directory/path\n",
    "        input_frequency.delete(0, tk.END)\n",
    "        input_frequency.insert(0, input_text)\n",
    "    except AttributeError:\n",
    "        status_bar.configure(foreground='red')\n",
    "        status_text.set('*ERROR* Please open a valid location for the Airport-Frequency Data file')\n",
    "        print(\"Please open a valid location for the Airport-Frequency Data file\")\n",
    "\n",
    "def open_file_4():\n",
    "    \"\"\"\n",
    "    Browse Cleaned Data File (JSON).\n",
    "    \"\"\"\n",
    "    global json_file\n",
    "    try:\n",
    "        file = filedialog.askopenfile(filetypes =[('JSON Files', '*.json')])\n",
    "        # read json file\n",
    "        json_file = pd.read_json(file)\n",
    "        input_text = file.name\n",
    "        # update input field with file upload directory/path\n",
    "        input_graph.delete(0, tk.END)\n",
    "        input_graph.insert(0, input_text)\n",
    "        status_text.set('Your JSON file has been loaded.')\n",
    "    except AttributeError or ValueError:\n",
    "        error_location()\n",
    "        print(\"Please open a valid location for the data file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-courtesy",
   "metadata": {},
   "source": [
    "<a name='generic'></a>\n",
    "## 6.5 Generic Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "republican-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_clean(df):\n",
    "    \"\"\"\n",
    "    Clean data generically.\n",
    "    \"\"\"\n",
    "    print(\"***Convert all column names to uppercase\")\n",
    "    df.columns = [x.upper() for x in df.columns]\n",
    "    \n",
    "    # get all categorical features\n",
    "    cat_features = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "    # get all numerical features\n",
    "    num_features = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    \n",
    "    # replace NaN in categorical features with 'Missing'\n",
    "    print(\"***Mark missing values in categorical features as 'Missing'\")   \n",
    "    for cat in cat_features:\n",
    "        df[cat].replace(to_replace = np.nan, value = \"Missing\",inplace=True)\n",
    "            \n",
    "    # replace NaN in numerical features with median of the column\n",
    "    print(\"***Replace missing values in numerical features with median of the column\")  \n",
    "    for num in num_features:\n",
    "        df[num].fillna(df[num].median(), inplace=True)\n",
    "        \n",
    "    print(\"***Make some columns into upper case\") \n",
    "    # turn yes/no into 1/0 in 'SCHEDULED_SERVICE' in 'airports.csv'\n",
    "    if 'SCHEDULED_SERVICE' in df.columns:\n",
    "        df[\"SCHEDULED_SERVICE\"] = pd.Series(np.where(df.SCHEDULED_SERVICE.values == 'yes', 1, 0), df.index)\n",
    "          \n",
    "    # make \"SURFACE\" in 'runways.csv' into upper case\n",
    "    if \"SURFACE\" in df.columns:\n",
    "        df[\"SURFACE\"] = df[\"SURFACE\"].str.upper()\n",
    "\n",
    "    # make \"DESCRIPTION\" in 'airport-frequencies.csv' into upper case\n",
    "    if \"DESCRIPTION\" in df.columns:\n",
    "        df[\"DESCRIPTION\"] = df[\"DESCRIPTION\"].str.upper()\n",
    "    \n",
    "    print(\"***Finish Cleaning \")\n",
    "    print(df.head())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-assets",
   "metadata": {},
   "source": [
    "<a name='select_type'></a>\n",
    "## 6.6 Select Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "approximate-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_type(x):\n",
    "    \"\"\"\n",
    "    Select types: large_airport, medium_airport, small airport.\n",
    "    Return True if the above type is selected else return False\n",
    "    \"\"\"\n",
    "    if x == \"large_airport\" :\n",
    "        return True\n",
    "    elif x == \"medium_airport\":\n",
    "        return True\n",
    "    elif x == \"small_airport\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-backup",
   "metadata": {},
   "source": [
    "<a name='clean_button'></a>\n",
    "## 6.7 Clean File Function Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "municipal-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_files():\n",
    "    \"\"\"\n",
    "    Clean File Function Button.\n",
    "    \"\"\"\n",
    "    global df_merge\n",
    "    status_preparing()\n",
    "    try: \n",
    "        # only clean if all files are present \n",
    "        if (len(input_frequency.get()) != 0) and (len(input_runway.get()) != 0) and (len(input_airport.get()) != 0):\n",
    "            global df1, df2, df3\n",
    "            status_cleaned()\n",
    "            \n",
    "            # clean and created subset of airport\n",
    "            df1 = generic_clean(df_airport)\n",
    "            # clean and created subset of runway\n",
    "            df2 = generic_clean(df_runway)\n",
    "            # clean and created subset of frequency\n",
    "            df3 = generic_clean(df_frequency)\n",
    "            \n",
    "            ### remove data from airports that have a 'type' 'closed' ###\n",
    "            # remove records\n",
    "            df_airports_cleaned_remove = df1[df1[\"TYPE\"]!=\"closed\"]\n",
    "            # reset index\n",
    "            df_airports_cleaned_remove = df_airports_cleaned_remove.reset_index(drop=True)\n",
    "\n",
    "            ### get only UK (GB) airports ###\n",
    "            # get uk records\n",
    "            df_airports_cleaned_remove_uk = df_airports_cleaned_remove[df_airports_cleaned_remove[\"ISO_COUNTRY\"]==\"GB\"]\n",
    "            # reset index\n",
    "            df_airports_cleaned_remove_uk = df_airports_cleaned_remove_uk.reset_index(drop=True)\n",
    "            \n",
    "            ### extract \"type\" column out into a new column, one for each category of airport, \n",
    "            ### for all UK(GB) airports, i.e., large_airport, medium_airport, small_airport ###\n",
    "            df_airports_cleaned_remove_uk[\"TYPE_SELECTED\"] = df_airports_cleaned_remove_uk[\"TYPE\"].apply(select_type)\n",
    "            \n",
    "            ### join each category, large_airport, medium_airport, small_airport \n",
    "            ### to the communication frequencies ‘ frequency_mhz’ \n",
    "            ### that the airport uses for communication ensuring \n",
    "            ### that each airport in all categories is correctly matched with its communication frequencies\n",
    "            # select only large_airport, medium_airport, small_airport \n",
    "            df_airports_selected = df_airports_cleaned_remove_uk[df_airports_cleaned_remove_uk[\"TYPE_SELECTED\"]==True]\n",
    "            # reset index\n",
    "            df_airports_selected = df_airports_selected.reset_index(drop=True)\n",
    "            \n",
    "            # join df_airports_selected and df_frequencies_cleaned on ID\n",
    "            df_merge = pd.merge(df_airports_selected, df3, left_on=\"IDENT\", right_on=\"AIRPORT_IDENT\", how=\"inner\")\n",
    "            # reset index\n",
    "            df_merge = df_merge.reset_index(drop=True)\n",
    "            print(df_merge.head())\n",
    "           \n",
    "            # export as JSON file\n",
    "            export_json(df_merge)\n",
    "\n",
    "        else:\n",
    "            # if one or more files are not present, there is an error\n",
    "            error_files()\n",
    "\n",
    "    except NameError:\n",
    "        print(\"There is an issue with one or more of your file uploads, please check them then try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-bicycle",
   "metadata": {},
   "source": [
    "<a name='data_wrangling'></a>\n",
    "## 6.8 Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "found-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_wrangling():\n",
    "    \"\"\"\n",
    "    Data Wrangling.\n",
    "    \"\"\"\n",
    "    global df_small, df_medium, \\\n",
    "            df_la, df_large\n",
    "    # select records of \"small_airport\"\n",
    "    df_small = json_file[json_file[\"TYPE_x\"]==\"small_airport\"]\n",
    "    # select records of \"small_airport\"\n",
    "    df_medium = json_file[json_file[\"TYPE_x\"]==\"medium_airport\"]\n",
    "    # select records for 'large_airport'\n",
    "    df_la = json_file[json_file[\"TYPE_x\"]==\"large_airport\"]\n",
    "    # select records for frequencies more than 100 mhz\n",
    "    df_large = json_file[json_file[\"FREQUENCY_MHZ\"]>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immediate-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_values_higher():\n",
    "    \"\"\"\n",
    "    Delete values higher than the chosen value.\n",
    "    \"\"\"\n",
    "    global a, b, c, d\n",
    "    # delete values beyond a specified value\n",
    "    a = df_la[\"FREQUENCY_MHZ\"]\n",
    "    b = df_medium[\"FREQUENCY_MHZ\"]\n",
    "    c = df_small[\"FREQUENCY_MHZ\"]\n",
    "    d = df_large[\"FREQUENCY_MHZ\"]\n",
    "    a = a[a <= var.get()]  \n",
    "    b = b[b <= var.get()] \n",
    "    c = c[c <= var.get()] \n",
    "    d = d[d <= var.get()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-offering",
   "metadata": {},
   "source": [
    "<a name='calculate'></a>\n",
    "## 6.9 Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baking-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(x):\n",
    "    \"\"\"\n",
    "    Calculate the mean, mode, median, \n",
    "    and standard deviation of frequency of the input airport.\n",
    "    \"\"\"\n",
    "    #calculate the mean\n",
    "    mean = x.mean()\n",
    "    # calculate the mode\n",
    "    mode = x.mode()\n",
    "    # convert series of mode into list\n",
    "    mode = mode.tolist()\n",
    "    # calculate median\n",
    "    median = x.median()\n",
    "    # calculate standard deviation\n",
    "    sd = np.std(x)\n",
    "    return mean, mode, median, sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-spray",
   "metadata": {},
   "source": [
    "<a name='table'></a>\n",
    "## 6.10 Table of Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graduate-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table():\n",
    "    \"\"\"\n",
    "    Produce a table of mean, mode and median \n",
    "    for frequencies of different categories of airport.\n",
    "    \"\"\"\n",
    "    global table_la\n",
    "    # delete values\n",
    "    delete_values_higher()\n",
    "    # calculate statistics\n",
    "    stat_small = list(calculate(c))\n",
    "    stat_medium = list(calculate(b))\n",
    "    stat_la = list(calculate(a))\n",
    "    stat_large = list(calculate(d))\n",
    "    table_la = pd.DataFrame([stat_la])\n",
    "    table_la.columns =['Mean', 'Mode', 'Median', 'Standard Deviation']\n",
    "    # append rows\n",
    "    table_la = table_la.append(pd.Series(stat_medium, index = table_la.columns), ignore_index=True)\n",
    "    table_la = table_la.append(pd.Series(stat_small, index = table_la.columns), ignore_index=True)\n",
    "    table_la = table_la.append(pd.Series(stat_large, index = table_la.columns), ignore_index=True)\n",
    "    # change the row indexes\n",
    "    table_la.index = ['large_airport', 'medium_airport', 'small_airport', 'Frequencies more than 100 mhz']\n",
    "    cols = list(table_la.columns)\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Statistics of Airport Frequencies\")\n",
    "    tree = ttk.Treeview(root)\n",
    "    tree.pack()\n",
    "    tree[\"columns\"] = cols\n",
    "    for i in cols:\n",
    "        tree.column(i, anchor=\"w\")\n",
    "        tree.heading(i, text=i, anchor='w')\n",
    "\n",
    "    for index, row in table_la.iloc[::-1].iterrows():\n",
    "        tree.insert(\"\",0,text=index,values=list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-homeless",
   "metadata": {},
   "source": [
    "<a name='start_graphs'></a>\n",
    "## 6.11 Create Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ancient-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graphs():\n",
    "    \"\"\"\n",
    "    Create graphs.\n",
    "    \"\"\"\n",
    "    # name graph window\n",
    "    global graphs, graph_box_whisker, \\\n",
    "    graph_histogram1, graph_histogram2, graph_histogram3\n",
    "    graphs = plt.figure()\n",
    "    graphs.set_figwidth(35) \n",
    "    graphs.set_figheight(6) \n",
    "    # add location of subplots\n",
    "    graph_box_whisker = graphs.add_subplot(1, 4, 1)\n",
    "    graph_histogram1 = graphs.add_subplot(1, 4, 2)\n",
    "    graph_histogram2 = graphs.add_subplot(1, 4, 3)\n",
    "    graph_histogram3 = graphs.add_subplot(1, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-connectivity",
   "metadata": {},
   "source": [
    "<a name='box_whisker'></a>\n",
    "## 6.12 Box-and-Whisker Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "developmental-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_whisker():\n",
    "    \"\"\"\n",
    "    Produce the box-and-whisker plots of frequencies for all airports.\n",
    "    \"\"\"\n",
    "    # delete values\n",
    "    delete_values_higher()\n",
    "    # produce the box-and-whisker plots of frequencies for all airports\n",
    "    data = [a, b, c]\n",
    "    # Creating plot\n",
    "    graph_box_whisker.boxplot(data, showfliers=False)\n",
    "    graph_box_whisker.set_xticks([1, 2, 3], ['large', 'medium', 'small'])\n",
    "    graph_box_whisker.set_ylabel(\"Frequency (MHz)\")\n",
    "    graph_box_whisker.set_xlabel(\"Airport\")\n",
    "    graph_box_whisker.set_title(\"Box-and-whisker plots of Airport Frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-olive",
   "metadata": {},
   "source": [
    "<a name='histograms'></a>\n",
    "## 6.13 Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cardiac-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms():\n",
    "    \"\"\"\n",
    "    Produce histograms of frequencies for all airports.\n",
    "    \"\"\"\n",
    "    binwidth = 10\n",
    "    # delete values\n",
    "    delete_values_higher()\n",
    "    # plot histogram of frequency of \"small_airport\"\n",
    "    # select records of \"small_airport\"\n",
    "    data = c\n",
    "    graph_histogram1.hist(data, bins=np.arange(min(data), max(data) + binwidth, binwidth), alpha=0.5, histtype='bar', ec='black')\n",
    "    graph_histogram1.set_title(\"Histogram of Frequency of 'small_airport'\")\n",
    "    graph_histogram1.set_xlabel(\"Frequency (MHz)\")\n",
    "    graph_histogram1.set_ylabel(\"Count\")\n",
    "\n",
    "    # plot histogram of frequency of \"medium_airport\"\n",
    "    # select records of \"small_airport\"\n",
    "    data = b\n",
    "    graph_histogram2.hist(data, bins=np.arange(min(data), max(data) + binwidth, binwidth), alpha=0.5, histtype='bar', ec='black')\n",
    "    graph_histogram2.set_title(\"Histogram of Frequency of 'medium_airport'\")\n",
    "    graph_histogram2.set_xlabel(\"Frequency (MHz)\")\n",
    "    graph_histogram2.set_ylabel(\"Count\")\n",
    "\n",
    "    # plot histogram of frequency of \"large_airport\"\n",
    "    # select records for 'large_airport'\n",
    "    data = a\n",
    "    graph_histogram3.hist(data, bins=np.arange(min(data), max(data) + binwidth, binwidth), alpha=0.5, histtype='bar', ec='black')\n",
    "    graph_histogram3.set_title(\"Histogram of Frequency of 'large_airport'\")\n",
    "    graph_histogram3.set_xlabel(\"Frequency (MHz)\")\n",
    "    graph_histogram3.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-kinase",
   "metadata": {},
   "source": [
    "<a name='graph_selection'></a>\n",
    "## 6.14 Graphs Function Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sacred-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_graph():\n",
    "    \"\"\"\n",
    "    Select graphs.\n",
    "    \"\"\"\n",
    "    data_wrangling()\n",
    "    create_graphs()\n",
    "    if graph.get() == 1:\n",
    "        # produce the box-and-whisker plots of frequencies for all airports\n",
    "        box_whisker()\n",
    "    if v_stat.get() == 1:\n",
    "        # produce a table of mean, mode and median \n",
    "        # for frequencies of different categories of airport\n",
    "        table()\n",
    "    if v_hist.get() == 1:\n",
    "        # produce histograms\n",
    "        histograms()\n",
    "    else:\n",
    "        status_text.set('No graphs have been selected. Please pick at least 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-computer",
   "metadata": {},
   "source": [
    "<a name='visualize_data'></a>\n",
    "## 6.15 Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "structural-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data():\n",
    "    \"\"\"\n",
    "    Visualize Data.\n",
    "    \"\"\"\n",
    "    if len(input_graph.get()) == 0:\n",
    "        error_files()\n",
    "    else:\n",
    "        select_graph()\n",
    "        status_text.set('*STATUS* Building your graphs! Check new window')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-vietnam",
   "metadata": {},
   "source": [
    "<a name='export_graphs'></a>\n",
    "## 6.16 Export Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "disciplinary-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_graphs():\n",
    "    \"\"\"\n",
    "    Export graphs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # select graphs\n",
    "        select_graph()\n",
    "        # export graphs as image\n",
    "        graphs.savefig('plots.png')\n",
    "        # export data file if statistics table is selected\n",
    "        if v_stat.get() == 1:\n",
    "             table_la.to_csv(\"stat_airport_freq.csv\")\n",
    "        status_text.set('Your graph(s)/table have been exported into the same folder!')\n",
    "    except NameError:\n",
    "        error_location()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-obligation",
   "metadata": {},
   "source": [
    "<a name='content'></a>\n",
    "## 7 Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-writing",
   "metadata": {},
   "source": [
    "<a name='tab1'></a>\n",
    "## 7.1 Tab 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hawaiian-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add text label\n",
    "ttk.Label(clean_tab, text=\"Airport Data File\", \\\n",
    "          style=\"STD.Label\").grid(row= 1, column=0, padx=10, pady=10, sticky=W)\n",
    "ttk.Label(clean_tab, text=\"Runway Data File\", \\\n",
    "          style=\"STD.Label\").grid(row= 2, column=0, padx=10, pady=10, sticky=W)\n",
    "ttk.Label(clean_tab, text=\"Airport-Frequency Data File\", \\\n",
    "          style=\"STD.Label\").grid(row= 3, column=0, padx=10, pady=10, sticky=W)\n",
    "ttk.Label(clean_tab, text=\"Ouput File Name\", \\\n",
    "          style=\"STD.Label\").grid(row=4, column=0, padx=10, pady=25, sticky=W)\n",
    "ttk.Label(clean_tab, text=\"Please upload your data files (.csv) to be cleaned\", \\\n",
    "          style='STD.Label').grid(row=0, column=0, columnspan=3, padx=10, pady=30)\n",
    "\n",
    "# add input fields to clean_tab\n",
    "input_airport = ttk.Entry(clean_tab)\n",
    "input_runway = ttk.Entry(clean_tab)\n",
    "input_frequency = ttk.Entry(clean_tab)\n",
    "input_filename = ttk.Entry(clean_tab)\n",
    "\n",
    "# position of input fields\n",
    "input_airport.grid(row=1, column=1, padx=5, pady=0)\n",
    "input_runway.grid(row=2, column=1, padx=5, pady=0)\n",
    "input_frequency.grid(row=3, column=1, padx=5, pady=0)\n",
    "input_filename.grid(row=4, column=1, padx=0, pady=0)\n",
    "\n",
    "# file browse buttons\n",
    "btn_browse_1 = ttk.Button(clean_tab, text=\"Browse\", command = lambda:open_file_1())\n",
    "btn_browse_2 = ttk.Button(clean_tab, text=\"Browse\", command = lambda:open_file_2())\n",
    "btn_browse_3 = ttk.Button(clean_tab, text=\"Browse\", command = lambda:open_file_3())\n",
    "\n",
    "# browse button layout  \n",
    "btn_browse_1.grid(row=1, column=2)\n",
    "btn_browse_2.grid(row=2, column=2)\n",
    "btn_browse_3.grid(row=3, column=2)\n",
    "\n",
    "# action buttons\n",
    "btn_clean = ttk.Button(clean_tab, text=\"Clean & Export\", command= lambda:clean_files())\n",
    "btn_close = ttk.Button(clean_tab, text=\"Close\", command=exit)\n",
    "\n",
    "# action button layout\n",
    "btn_clean.grid(row=5, column=1)\n",
    "btn_close.grid(row=5, column=2, sticky=W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-worcester",
   "metadata": {},
   "source": [
    "<a name='tab2'></a>\n",
    "## 7.2 Tab 2: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttk.Label(graph_tab, \\\n",
    "          text=\"Please upload your cleaned data file for data visualization/analysis\", \\\n",
    "          style='STD.Label').grid(row=0, column=0, columnspan=3, padx=10, pady=20)\n",
    "\n",
    "##############################################################################################\n",
    "# I. upload data file \n",
    "##############################################################################################\n",
    "ttk.Label(graph_tab, text=\"Cleaned Data File\", \\\n",
    "          style='STD.Label').grid(row=1, column=0, padx=10, pady=10, sticky=W)\n",
    "\n",
    "# add input fields to graph_tab\n",
    "input_graph = ttk.Entry(graph_tab)\n",
    "# position of input fields\n",
    "input_graph.grid(row=1, column=1, sticky=W)\n",
    "\n",
    "# browse button \n",
    "btn_graph_browse = ttk.Button(graph_tab, text=\"Browse\", command = lambda:open_file_4())\n",
    "btn_graph_browse.grid(row=1, column=2, sticky=W)\n",
    "\n",
    "##############################################################################################\n",
    "# II. select graphs\n",
    "##############################################################################################\n",
    "ttk.Label(graph_tab, \\\n",
    "          text=\"Select the visualisation (s)/table you would like to produce\", \\\n",
    "          style=\"STD.Label\").grid(row= 2, column=0, padx=10, pady=10, sticky=W, columnspan=3)\n",
    "\n",
    "# check boxes\n",
    "v_stat = tk.IntVar()\n",
    "v_hist = tk.IntVar()\n",
    "graph = tk.IntVar()\n",
    "\n",
    "# table\n",
    "check_table = Checkbutton(graph_tab, \\\n",
    "                        text=\"Statistics of Airport Frequencies\", variable=v_stat, \\\n",
    "                        onvalue=1, offvalue=0, background='#ececec')\n",
    "check_table.grid(row=3,column=0, sticky=W,columnspan=2,  padx=5, pady=5)\n",
    "\n",
    "# histograms\n",
    "check_hist = Checkbutton(graph_tab, \\\n",
    "                      text=\"Histograms of Airport Frequencies\", variable=v_hist, \\\n",
    "                      onvalue=1, offvalue=0, background='#ececec')\n",
    "check_hist.grid(row=3,column=1, sticky=W)\n",
    "\n",
    "# box-and-whisker plots \n",
    "check_box = Checkbutton(graph_tab, \\\n",
    "                        text=\"Box-and-whisker plots of Airport Frequencies\", \\\n",
    "                        variable=graph, onvalue=1, offvalue=0, background='#ececec')\n",
    "check_box.grid(row=4,column=0, sticky=W, columnspan=3, padx=5)\n",
    "\n",
    "# Remove values between + Slider\n",
    "ttk.Label(graph_tab, text=\"Delete values higher than the chosen value\", \\\n",
    "          style=\"STD.Label\").grid(row= 5, column=0, padx=10, sticky=W)\n",
    "# Add slider so they dont enter wrong values\n",
    "var = DoubleVar()\n",
    "slider_max = Scale(graph_tab, from_=0, to=1000, \\\n",
    "                   orient=HORIZONTAL, bg = \"#ececec\", length=200, variable=var)\n",
    "slider_max.grid(row=5, column=1, columnspan=2, sticky=W, padx=5)\n",
    "\n",
    "\n",
    "# option buttons \n",
    "# reset\n",
    "btn_export = ttk.Button(graph_tab, text=\"Export\", command = lambda:export_graphs())\n",
    "btn_export.grid(row=9, column=0, padx=0, sticky=E)\n",
    "\n",
    "# visualize data\n",
    "btn_graph = ttk.Button(graph_tab, text=\"Visualize Data\", command = lambda:visualize_data())\n",
    "btn_graph.grid(row=9, column=1, pady=20)\n",
    "\n",
    "# close button\n",
    "btn_close = ttk.Button(graph_tab, text=\"Close\", command=exit)\n",
    "btn_close.grid(row=9, column=2, sticky=W)\n",
    "\n",
    "# execute Tkinter\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-arrow",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
